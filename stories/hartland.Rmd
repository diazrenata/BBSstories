---
title: "BBS route that goes by Hartland"
output: 
    github_document:
       df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(bbstrends)
library(dplyr)
library(ggplot2)
```


### Load specific route

The New Hartford route goes up and down Riverton Road and was started in 1994. It feels pretty auspicious. It is route 102, region 18.

```{r load route}

ibd <- readRDS("C:\\Users\\diaz.renata\\Documents\\GitHub\\BBSsize\\analysis\\isd_data\\ibd_isd_bbs_rtrg_102_18.Rds")
```

Here are the species present in this route over the past 25 years:

```{r species list for fun}

ibd_species <- ibd %>%
  select(id, ind_size) %>%
  group_by(id) %>%
  summarize(mean_size = mean(ind_size)) %>%
  ungroup() %>%
  arrange(mean_size)

species_list <- read.csv("C:\\Users\\diaz.renata\\Documents\\GitHub\\BBSsize\\analysis\\species_data\\species_list_working.csv", stringsAsFactors = F)

species_list <- species_list %>%
  select(id, english_common_name)

ibd_species <- left_join(ibd_species, species_list) %>%
  distinct()

ibd_species

```

Here is how species richness, abundance, biomass, and energy have changed over those years:

```{r state variables}

sv <- ibd %>%
  group_by(year) %>%
  summarize(richness = length(unique(id)),
            abundance = dplyr::n(),
            biomass = sum(ind_size),
            energy = sum(ind_b)) %>%
  ungroup() %>%
  mutate(mean_energy = energy / abundance,
         mean_mass = biomass/abundance)


sv_long <- sv %>%
  tidyr::pivot_longer(-year, names_to = "currency", values_to = "value")

ggplot(filter(sv_long, !grepl("mean", currency)), aes(x = year, y = value, color = currency)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  scale_color_viridis_d(end = .8) +
  theme(legend.position = "none") +
  facet_wrap(vars(currency), scales = "free_y")

```

Here is population abundances:

```{r pops, fig.dim = c(10, 6)}

pops <- ibd %>%
  select(year, id) %>%
  group_by(year, id) %>%
  summarize(abund = dplyr::n()) %>%
  ungroup() %>%
  group_by(year) %>%
  mutate(annual_abund = sum(abund)) %>%
  ungroup() %>%
  group_by_all() %>%
  mutate(prop_abund = abund / annual_abund) %>%
  ungroup()

ggplot(pops, aes(year, (prop_abund), color = id)) +
  geom_line() +
  theme_bw() +
  scale_color_viridis_d() +
  theme(legend.position = "none")

```

### Trends/tradeoffs in E and N

We can do some (crude) linear model fitting. I've generally been finding that lms are OK, with caveats:

- you do want to check for autocorrelation
- the normal q-q plots are often kind of wonky


```{r lms}

sv_long <- sv_long %>%
  group_by(currency) %>%
  mutate(scaled_value = scale(value)) %>%
  ungroup()

abund_lm <- lm(scaled_value ~ year, data = filter(sv_long, currency == "abundance"))

summary(abund_lm)

confint(abund_lm)

sv$abund_prediction = predict(abund_lm)

ggplot(sv, aes(x = year, y = scale(abundance))) +
  geom_point() +
  geom_line(aes(x = year, y = abund_prediction)) + 
  theme_bw()

hist(resid(abund_lm))

energy_lm <- lm(scaled_value ~ year, data = filter(sv_long, currency == "energy"))

summary(energy_lm)

confint(energy_lm)

sv$energy_prediction <- predict(energy_lm)


ggplot(sv, aes(x = year, y = scale(energy))) +
  geom_point() +
  geom_line(aes(x = year, y = energy_prediction)) + 
  theme_bw()

hist(resid(energy_lm))

```

Important points: 

* p = .04 for abundance, but .55 (!) for energy
* confidence interval for slope for abundance gets close to 0; estimate is -.055 (this is on scaled)
* r2 for abundance is around .13-.15 (adj v nonadj). 
* contrasted to energy, where the slope estimate is right on 0 and the r2 is .01 to -.02 (adj v nonadj)! 


I've played a bit with autocorrelation and transformations, but trying not to get hung up on p values. Basically, the lms are generally aligning with what looks intuitive from the plots: a gentle decline in individual abundance, but no signal in energy. 

Importantly, even though the average slope for energy is pretty close to 0, I would *not* call this compensation in the sense that the size distribution is shifting such that the same amount of energy gets divided among varying numbers of individiuals. Under that scenario, we'd expect per capita energy use to trade off with abundance: when abundance is low, per capita energy use should be high to compensate. That is not what we see: 

```{r abund v compensation}

ggplot(sv, aes(x = abundance, y = mean_energy)) +
  geom_point() +
  theme_bw()

summary(lm(scale(mean_energy) ~ scale(abundance), sv))

```

There's pretty much no support for the notion that mean energy use declines with increasing abundance.


It looks to me a lot more like energy varies a lot but not systematically with time. Energy is also much more variable than abundance:

```{r variability}

print("energy sd/mean")
sd(sv$energy) / mean(sv$energy)

print("abundance sd/mean")
sd(sv$abundance) / mean(sv$abundance)

```


Another notion is that energy should maybe track abundance? We have already seen that energy is more variable than abundance and that the overall trend for energy is not the same as the one for abundance. Here is the extent to which abundance predicts energy:

```{r abund v energy}

energy_abund_lm <- (lm(scale(energy) ~ scale(abundance), data = sv))

sv$e_from_n <- predict(energy_abund_lm)

ggplot(sv, aes(x = scale(abundance), y = scale(energy))) +
  geom_point() +
  geom_line(aes(x = scale(abundance), y = e_from_n)) +
  theme_bw()

summary(energy_abund_lm)
hist(resid(energy_abund_lm))
```

So....decent, but a fair amount of error remaining. It's difficult to know how much error is _a lot_ of error for an ecological community a priori. We can say provisionally that this is probably not the reflection of an extremely high-fidelity, controlled, idealized amplification/dampening of a fixed energy distribution: there's clearly play. But then again, we don't expect communities to behave in highly controlled, high-fidelity, idealized ways! There are all kinds of sources of measurement error etc, plus stochasticity, plus small N sampling issues. 


### Fixed or variable ISDs

One interesting way energy could track abundance would be if there were essentially one ISD for a community that endured over time, and the ISD we observe at each time point is just the result of drawing $N_t$ individuals from that distribution. In that scenario we would expect higher $N_t$ to give us more energy, but there is still room for error around that relationship. 

There are a variety of ways we could construct our ur-ISD:

- All of the individuals we have ever observed.
    - This is straightforward but will allow us to put more weight into time points with higher N. 
- Take a mean of the ISDs from every time step.
    - This can become distorted by sharp distributions from low N.
    
```{r compare ur isd methods}

all_individuals_isd <- density(log(ibd$ind_size), from = 0, to = 1.2 * max(log(ibd$ind_size)), n = 8192)

all_individuals_isd <- data.frame(
  size = all_individuals_isd$x,
  density = all_individuals_isd$y / sum(all_individuals_isd$y)
)

make_year_isd <- function(thisyear, ibd) {
  this_ibd <- filter(ibd, year == thisyear)
  this_isd <- density(log(this_ibd$ind_size), from = 0, to = 1.2 * max(log(ibd$ind_size)), n = 8192)
  
  return(data.frame(x =this_isd$x,
                    y = this_isd$y / sum(this_isd$y),
                    year = thisyear))
}


year_isds <- lapply(unique(ibd$year), FUN = make_year_isd, ibd = ibd)


year_isds <- bind_rows(year_isds)

mean_year_isds <- year_isds %>%
  group_by(x) %>%
  summarize(mean_density = mean(y)) %>%
  ungroup() %>%
  rename(size = x)

gridExtra::grid.arrange(
  grobs = list(ggplot(mean_year_isds, aes(size, mean_density)) + 
  geom_line() +
  theme_bw() +
  ggtitle("Mean of annual ISDs"),
  
ggplot(all_individuals_isd, aes(size, density)) +
  geom_line() +
  theme_bw() +
  ggtitle("All individuals")
), nrow = 1)

ggplot(all_individuals_isd, aes(size, density)) +
  geom_line() +
  geom_line(data = mean_year_isds, aes(size, mean_density), color = "blue") +
  theme_bw() +
  ggtitle("Both at once for scale")
```

The mean one is considerably broader/less well defined than the all-the-individuals-at-once one. I'm not sure what to make of that. 




Alternatively, there could be substantively different underlying ISDs we are drawing our $N_t$ individuals from, and the underlying ISDs could vary systematically over time or orthogonal/not-detectably-parallel-to time. 


```{r isd playing}


overall_isd <- data.frame(
  x =  density(log(ibd$ind_size), from = 0, to = 1.2 * max(log(ibd$ind_size)), n = 8192)$x,
  y = density(log(ibd$ind_size), from = 0, to = 1.2 * max(log(ibd$ind_size)), n = 8192)$y)

overall_isd <- overall_isd %>%
  mutate(y = y / sum(y))

make_year_isd <- function(thisyear, ibd) {
  this_ibd <- filter(ibd, year == thisyear)
  this_isd <- density(log(this_ibd$ind_size), from = 0, to = 1.2 * max(log(ibd$ind_size)), n = 8192)
  
  return(data.frame(x =this_isd$x,
                    y = this_isd$y / sum(this_isd$y),
                    year = thisyear))
}


year_isds <- lapply(unique(ibd$year), FUN = make_year_isd, ibd = ibd)


year_isds <- bind_rows(year_isds)

ggplot(overall_isd, aes(x, y)) +
  geom_point() +
  theme_bw() +
  geom_line(data = year_isds, aes(x = x, y = y, group = year, color = as.factor(year)), alpha = .3) +
  theme(legend.position = "none")

```

### Randomizing the ISD

```{r randomize isd}

randomized_isd_e <- function(thisyear, ibd) {
  
  this_abund <- nrow(ibd [ which(ibd$year == thisyear), ])
  
  sampled_ind_b <- ibd$ind_b[ sample.int(nrow(ibd), size = this_abund, replace = F)]
  
  return(data.frame(
    year = thisyear,
    energy = sum(sampled_ind_b)))

}



randomized_es <- lapply(unique(sv$year), FUN = function(thisyear, ibd, times) return(bind_rows(replicate(n = times, expr = randomized_isd_e(thisyear = thisyear, ibd = ibd), simplify = F), .id = "rep")), ibd = ibd, times = 1000)


randomized_es <- bind_rows(randomized_es)

ggplot(randomized_es, aes(year, energy, group = year)) +
  geom_violin() +
  geom_point(data = sv, color = "red") +
  theme_bw()

```


Here is something I've done mostly following intuition. I think it shows how each year's observed total energy use scores relative to if it had tracked an overall single ISD. This is a bootstrapping/simulating approach intended to get a sense of some of the variation from lowish N, and start to partition abundance from ISD.

The violins represent the distribution of *total energy values* for 1000 bootstrap sampled ISDs. Each simulated ISD is a draw of the *observed number of individuals* from the pool of *all individuals observed across all years*. The pool includes the individuals actually observed that year. I've done it with or without replacement and I don't see a big obvious difference, but there are numerous questions in a similar vein that one could chase down. You could do an ISD as equal weight to each timestep (regardless of abundance) and then the mean density at each body size; that would remove some weight from time steps with high abundances. It also might be preferable to remove the observed year from the pool. 

So one thing I find interesting about this exercise is to ask whether the position of the observed E shifts systematically over time. 

I think, for observations to be consistent with a *single unchanging ISD* from which we draw N individuals at random every year, you'd expect the total E to track the violins. 

It might be interesting to look at comparisons to the overall ISD, vs a pool from a local short time period, vs a pool from the same number of time steps randomly distributed. So, how does E in 1990 compare to a random draw from a pool of `r c(1988, 1989, 1991, 1992)`, vs a random draw from a pool of  `r sample(c(1994:1989, 1991:2019), size = 4, replace = F)`? If observations are closer to a local moving average ISD, than to one randomly dispersed in time, you have some kind of temporal structure in the variability. But if not, there's variability but it's not structured temporally. 

